\chapter{Реализация компонентов и приложения-мигратора} \label{ch:ch3}
После того как команда определилась с процессом миграции, параллельно началась разработка как компонентов, так и приложения-мигратора.
В этой главе будут приведены листинги с их реализацией и пояснениями.

\section{Реализация компонентов} \label{sec:components-impl}
Изначально большая часть ресурса была брошена на разработку стандартизированных пайплайнов — тех самых компонентов в терминологии GitLab.
Такое распределение отчасти связано с тем, что миграцией занималась команда C\# разработчиков, которые не столь активно до этого работали
с bash скриптами\cite{bash} и инфраструктурными инструментами.

Тем не менее во время написания компонентов выделились два их вида, речь о которых пойдет далее.
Стоит отметить, что выработавшиеся подходы и названия являются терминологией внутри компании,
потому что GitLab в документации не давал обозначения тем вещам, которые мы упоминали часто, но для них не было слова.

\subsection{Компонентный конвейер} \label{subsec:component-pipeline}
В главе \enquote{Использование компонентов} упоминалось,
что GitLab предоставляет возможность подключать готовые конвейеры как нисходящие.
Именно поэтому в команде конвейерами также стали называть готовые шаблоны, которые можно подключить
к основному, но при этом нельзя расширить как задачу.
На листинге ~\ref{lst:component-pipeline} представлен код такого конвейера.
Он используется для тестирования Ansible ролей при помощи \texttt{Molecule}\cite{molecule}.

\begin{lstlisting}[language=yaml,label={lst:component-pipeline},caption={Компонентный конвейер тестирования через Molecule}]
# Спецификация входных параметров компонента
spec:
  inputs:
    # Параметр команды для выполнения Molecule
    molecule-command:
      # Описание параметра
      description: "Command to run on molecule"
      # Значение по умолчанию - запуск тестов
      default: "test"
    # Параметр Docker-образа для тестирования
    molecule-image:
      # Тип параметра - строка
      type: string
      # Описание образа
      description: "Docker image used for running Molecule tests in the pipeline"
      # Образ по умолчанию из Yandex Container Registry
      default: cr.yandex/crpcl8cpek7o88jk1vg7/ansible-molecule:latest
    # Параметр рабочей директории для тестов
    molecule-working-dir:
      # Тип параметра - строка
      type: string
      # Подробное описание назначения
      description: "The working directory where Molecule tests are executed. This directory is set as the MOLECULE_PROJECT_DIRECTORY environment variable during the pipeline run."
      # Значение по умолчанию - текущая директория
      default: "./"
---
# Настройки рабочего процесса конвейера
workflow:
  auto_cancel:
    # Прерывание предыдущих запусков при новом коммите
    on_new_commit: interruptible
  rules:
    # Запуск конвейера всегда
    - when: always

# Настройки по умолчанию для всех задач
default:
  # Разрешение прерывания задач
  interruptible: true

# Определение стадий выполнения
stages:
  # Загрузка секретов
  - load-secrets
  # Выполнение тестов
  - test

# Подключение внешних компонентов
include:
  - component: $CI_SERVER_FQDN/system/components/load-vault-secrets/load-vault-secrets@2

# Задача загрузки секретов из Vault
load-vault-secrets:
  stage: load-secrets
  # Это использование задачи из внешнего компонента.
  # Внешние задачи подробно описаны в следующей главе.
  extends: .load-vault-secrets
  variables:
    # Токен доступа к GitHub
    stable: GH_FULL_TOKEN

# Основная задача тестирования с Molecule
molecule:
  # Использование Docker-образа из входных параметров
  image: $[[ inputs.molecule-image ]]
  stage: test
  services:
    # Docker-in-Docker сервис
    - name: cr.yandex/crp2cvbrp76d7dmfegco/docker.io/docker:20.10.16-dind
      variables:
        # Порт для проверки состояния Docker
        HEALTHCHECK_TCP_PORT: "2376"
  variables:
    # Включение цветного вывода Python
    PY_COLORS: '1'
    # Принудительное включение цветов Ansible
    ANSIBLE_FORCE_COLOR: '1'
    # Рабочая директория Molecule
    MOLECULE_PROJECT_DIRECTORY: $[[ inputs.molecule-working-dir ]]
  script:
    # Настройка авторизации GitLab
    - echo "Add gitlab authorization..."
    # Создание директории для SSH ключей
    - mkdir -p ~/.ssh
    # Декодирование SSH ключа
    - echo -e "$GITLAB_SSH_PRIVATE_KEY_BASE64" | base64 -d > ~/.ssh/gitlab_ssh.key
    # Установка прав доступа к SSH ключу
    - chmod 600 ~/.ssh/gitlab_ssh.key
    # Добавление известных хостов
    - echo -e "$GITLAB_KNOWN_HOSTS" > ~/.ssh/known_hosts
    # Настройка SSH команды для Git
    - export GIT_SSH_COMMAND="ssh -i ~/.ssh/gitlab_ssh.key"
    # Вывод рабочей директории
    - echo "MOLECULE_PROJECT_DIRECTORY= '$MOLECULE_PROJECT_DIRECTORY'"
    # Настройка Git URL для SSH
    - git config --global url."git@mindbox.gitlab.yandexcloud.net:".insteadOf "https://mindbox.gitlab.yandexcloud.net/"

    # Временная авторизация GitHub
    - git config --global url."https://octopus-mindbox:${GH_FULL_TOKEN}@github.com/mindbox-cloud".insteadOf "https://github.com/mindbox-cloud"
    # Переход в рабочую директорию с проверкой
    - cd "$MOLECULE_PROJECT_DIRECTORY" || exit 1
    # Выполнение команды Molecule
    - molecule $[[ inputs.molecule-command ]]
\end{lstlisting}

\subsection{Компонентный шаблон} \label{subsec:component-template}
В листинге ~\ref{lst:component-pipeline} с компонентным конвейером использовалась внешняя задача.
В Mindbox для хранения таких задач стали использовать файлы, которые получили название \enquote{шаблоны}.
Грубо говоря, эти шаблоны просто содержат описания задач, которые позже подключаются в конвейеры.
При подключении шаблона, в отличие от конвейера, GitLab не исполняет задачи.
Все дело в том, что задачи следуют конвенции GitLab: в начале названия они содержат точку.
Ключевое слово \texttt{extends} при подключении внешней задачи как бы сообщает, что текущая задача наследуется от какой-то другой.
В этом и заключается преимущество внешних задач — в них можно переопределить все параметры в рамках задачи.
Однако эта особенность также является недостатком:
дублирование подключения внешних задач из конвейера в конвейер противоречит изначальной цели стандартизации.
Код задания шаблона для задачи \texttt{load-vault-secrets} показан и прокомментирован на листинге ~\ref{lst:component-template}.

\begin{lstlisting}[language=yaml,label={lst:component-template},caption={Компонентный шаблон для load-vault-secret}]
# Спецификация входных параметров компонента
spec:
  # Секция входных параметров (пустая для данного компонента)
  inputs: {}

---

# Шаблон задачи для загрузки секретов из Vault
.load-vault-secrets:
  # Docker-образ с установленным Vault CLI
  image: cr.yandex/crpcl8cpek7o88jk1vg7/vault:latest
  tags:
    # Использование небольших раннеров
    - tiny
    # Раннеры в Yandex Cloud
    - yandex
  # Выполнение в предварительной стадии
  stage: .pre
  variables:
    # Переменные для различных окружений (значения задаются при использовании)
    omega:
    sigma:
    stable:
    staging:
  script:
    - |
      # Функция загрузки секретов с использованием JWT аутентификации
      function load_secrets {
        # Получение списка ключей из аргументов функции
        local keys="$@"
        # Адрес Vault сервера
        local vault_addr="$VAULT_ADDR"
        # JWT токен для аутентификации
        local vault_id_token="$VAULT_ID_TOKEN"

        # Проверка наличия ключей для обработки
        if [ -z "$keys" ]; then
          return
        fi

        # Информационное сообщение о начале загрузки
        echo "Load secrets from $vault_addr using JWT authentication"

        # Настройка пути и роли для JWT аутентификации по умолчанию
        local auth_path="jwt-gitlab-v2"
        local auth_role="gitlab-ci"

        # Получение токена доступа к Vault через JWT аутентификацию
        export VAULT_TOKEN=$(vault write -field=token auth/$auth_path/login role=$auth_role jwt=$vault_id_token)

        # Обработка каждого ключа из списка
        for key in $keys
        do
          # Информационное сообщение о текущем ключе
          echo "Processing key specification: $key"

          # Парсинг формата ключа: secret_path[:field][:env_key]
          # Извлечение пути к секрету (все до первого ':')
          secret_path="${key%%:*}"
          # Остаток строки после первого ':'
          remainder="${key#*:}"

          # Проверка наличия двоеточий в спецификации
          if [[ "$secret_path" == "$remainder" ]]; then
            # Нет двоеточий, только путь к секрету
            field="value"
            env_key="$secret_path"
          else
            # Есть минимум одно двоеточие
            # Поле - все до следующего ':'
            field="${remainder%%:*}"
            # Все после второго ':'
            env_key_part="${remainder#*:}"

            # Проверка наличия второго двоеточия
            if [[ "$field" == "$env_key_part" ]]; then
              # Только одно двоеточие: secret_path:field
              env_key="$secret_path"
            else
              # Два двоеточия: secret_path:field:env_key
              env_key="$env_key_part"
            fi
          fi

          # Определение полного пути в Vault
          if echo "$secret_path" | grep -q '/'; then
            # Путь уже содержит слеш
            full_key="$secret_path"
          else
            # Добавление префикса common/ для простых имен
            full_key="common/$secret_path"
          fi

          # Извлечение имени переменной окружения из полного пути
          if echo "$env_key" | grep -q '/'; then
            env_key=$(echo "$env_key" | sed 's/.*\///')
          fi

          # Вывод информации о параметрах обработки
          echo "  -> Vault path: $full_key"
          echo "  -> Field: $field"
          echo "  -> Environment variable: $env_key"

          # Информационное сообщение о выполняемой команде
          echo "Executing: vault kv get -mount gitlab -field=$field $full_key"
          # Получение значения секрета из Vault
          if value=$(vault kv get -mount gitlab -field=$field $full_key 2>&1); then
            # Успешное получение значения
            echo "  -> Success: Got value for $env_key"
            # Запись переменной в файл результатов
            echo "$env_key=$value" >> result.env
          else
            # Ошибка получения секрета
            echo "  -> ERROR: Failed to get value"
            echo "  -> Vault error: $value"
            echo "  -> FAILING JOB: Required secret not found"
            # Завершение работы с ошибкой
            exit 1
          fi
        done
      }
  artifacts:
    # Запрет доступа к артефактам из других задач
    access: 'none'
    reports:
      # Файл с переменными окружения для передачи в последующие задачи
      dotenv: result.env
\end{lstlisting}

\section{Реализация приложения-мигратора} \label{sec:migrator-impl}
Важно еще раз вспомнить, что одно из требований к переезду — не блокировать разработку.
Трудозатраты на полную миграцию команда оценила в 1 год, за это время точно будут появляться новые репозитории.
Чтобы их не потерять и перенести, в инструмент был добавлен функционал команд,
которые вызывались автоматически раз в определенное время при помощи уже известных конвейеров в GitLab.
Самой первой такой командой стал улучшенный скрипт, собирающий информацию о репозиториях и в этот раз автоматически вносящий изменения в файл с состоянием переноса.
Код этой команды представлен на листинге ~\ref{lst:update-migration-state-command}.

\newpage
\begin{lstlisting}[language=c,label={lst:update-migration-state-command},caption={Код команды обновления информации о репозиториях}]
// Подключение необходимых сервисов и библиотек
using Github.Application.Services;
using Lib.Commands;
using Microsoft.Extensions.Logging;
using Migration.Application.Services;

namespace Migration.Cli.Commands;

// Команда для обновления состояния миграции
internal class UpdateMigrationStateCommand(
    // Сервис для работы с состоянием миграции
    IMigrationStateService migrationStateService,
    // Сервис для работы с репозиториями
    IRepositoryService repositoryService,
    // Сервис для работы с GitHub репозиториями
    IGithubRepositoryService githubRepositoryService,
    // Логгер для записи информации о выполнении
    ILogger<UpdateMigrationStateCommand> logger
// Наследование от базовой команды с указанием имени и описания
) : CommandBase("update-migration-state", "Update Migration State")
{
    // Основной метод выполнения команды
    public override async Task ExecuteAsync(CancellationToken cancellationToken)
    {
        // Логирование начала получения списка репозиториев
        logger.LogInformation("list github repositories");

        // Получение информации о репозиториях из GitHub
        var repositoryInfos = await githubRepositoryService.ListRepositoriesAsync();
        // Проверка успешности получения данных
        if (repositoryInfos is null)
        {
            // Логирование ошибки при неудачном получении данных
            logger.LogError("Failed to load repositories from Github");
            // Завершение выполнения команды
            return;
        }

        // Логирование начала синхронизации репозиториев с состоянием миграции
        logger.LogInformation("reflect github repositories to migration state");
        // Обновление файла состояния миграции данными из GitHub
        await migrationStateService.UpdateMigrationStateFile(repositoryInfos);

        // Синхронизация активных репозиториев
        await SyncActiveRepositories();

        // Логирование завершения процесса обновления
        logger.LogInformation("update complete");
    }

    // Приватный метод для синхронизации активных репозиториев
    private async Task SyncActiveRepositories()
    {
        // Логирование начала получения списка активных репозиториев
        logger.LogInformation("list active repositories");
        // Получение списка всех переведенных репозиториев
        var repositories = migrationStateService.ListAllTranslated();

        // Логирование начала синхронизации активных репозиториев
        logger.LogInformation("sync active repositories");
        // Выполнение синхронизации репозиториев
        await repositoryService.SyncRepositoriesAsync(repositories);
    }
}
\end{lstlisting}

Кроме команд, также были реализованы шаги для каждой фазы.
На текущий момент их 26.
На листинге ~\ref{lst:internal-work-started-step} приведена реализация одного из шага первой фазы по уведомлению о начале переноса.

\begin{lstlisting}[language=c,label={lst:internal-work-started-step},caption={Код шага оповещения о старте начала работ}]
// Подключение сервиса для работы с циклами уведомлений
using Lib.Loop.Services;
// Подключение логирования Microsoft
using Microsoft.Extensions.Logging;
// Подключение доменных моделей миграции
using Migration.Domain;
// Подключение библиотеки для работы с union типами
using OneOf;

namespace Migration.Application.Internal.Execution.Stages.FirstPhase;

// Процессор стадии уведомления о начале внутренней работы
internal class InternalWorkStartNotifyingStageProcessor(
    // Сервис для отправки сообщений в Loop
    ILoopService loopService
// Реализация интерфейса процессора стадий
) : IStageProcessor
{
    // Асинхронный метод обработки стадии миграции
    public async Task<OneOf<RepositoryMigrationStage, string>> ProcessAsync(MigrationContext context, ILogger logger)
    {
        // Проверка типа миграции - пропуск
        if (context.MigrationType is MigrationType.Skip)
            // Возврат состояния завершенной миграции
            return RepositoryMigrationStage.Completed;

        // Проверка типа миграции - копирование
        if (context.MigrationType is MigrationType.Copy)
            // Переход к стадии начала миграции репозитория
            return RepositoryMigrationStage.RepositoryMigrationMarkedToStart;

        // Отправка уведомления команде о начале работы
        var result = await loopService.PostMessage(GenerateMessage(context), context.Team);
        // Проверка результата отправки сообщения
        if (result is not null)
        {
            // Возврат ошибки, если отправка не удалась
            return result;
        }

        // Возврат состояния успешного уведомления
        return RepositoryMigrationStage.InternalWorkStartNotified;
    }

    // Приватный метод генерации текста уведомления
    private string GenerateMessage(MigrationContext context) =>
        // Формирование сообщения с предупреждением о начале миграции
        $"Началась миграция пайплайна в репозитории: {context.RepositoryName}. ** Пожалуйста, не меняйте его Workflow ** ";
}
\end{lstlisting}

\section{Выводы} \label{sec:impl-conclusion}

Подводя итог, после этапа проектирования одновременно началась разработка как компонентов, так и мигратора.
При разработке компонентов были выделены два подхода: конвейеры и шаблоны.
Также для приложения-мигратора был разработан функционал команд, позволяющий автоматизировать действия, связанные с переездом репозиториев.
Помимо этого были написаны шаги мигратора, упрощающие процесс переноса.
